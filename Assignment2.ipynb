{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Pad sequences to ensure all reviews are the same length\n",
    "X_train = pad_sequences(X_train, maxlen=200)\n",
    "X_test = pad_sequences(X_test, maxlen=200)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=10000, output_dim=128))  # Removed input_length\n",
    "    model.add(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.6893 - loss: 0.5705 - val_accuracy: 0.8174 - val_loss: 0.4123\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.8643 - loss: 0.3353 - val_accuracy: 0.8374 - val_loss: 0.3844\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8865 - loss: 0.2888 - val_accuracy: 0.7818 - val_loss: 0.4494\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9067 - loss: 0.2423 - val_accuracy: 0.8340 - val_loss: 0.4103\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.9051 - loss: 0.2415 - val_accuracy: 0.7692 - val_loss: 0.4944\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.8765 - loss: 0.2989 - val_accuracy: 0.8288 - val_loss: 0.4408\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 52ms/step - accuracy: 0.9320 - loss: 0.1795 - val_accuracy: 0.8384 - val_loss: 0.4155\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 52ms/step - accuracy: 0.9509 - loss: 0.1367 - val_accuracy: 0.8388 - val_loss: 0.4487\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 51ms/step - accuracy: 0.9610 - loss: 0.1117 - val_accuracy: 0.8320 - val_loss: 0.5105\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 52ms/step - accuracy: 0.9745 - loss: 0.0764 - val_accuracy: 0.8350 - val_loss: 0.5605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a9b4fb29f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.8341 - loss: 0.5637\n",
      "Accuracy: 83.57999920845032\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "    return decoded_review\n",
    "\n",
    "# Decode the first 3 reviews in the test set\n",
    "sample_reviews = [decode_review(X_test[i]) for i in range(3)]\n",
    "\n",
    "# Preprocess reviews\n",
    "def preprocess_reviews(reviews):\n",
    "    sequences = imdb.get_word_index()\n",
    "    indices = [[sequences.get(word, 0) for word in review.split()] for review in reviews]\n",
    "    return pad_sequences(indices, maxlen=200)\n",
    "\n",
    "preprocessed_reviews = preprocess_reviews(sample_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "Review: \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss\"\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: \"psychological ? it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the ? moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual ? and desperation be patient ? up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to ? a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\"\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: \"everyone's horror the ? promptly eats the mayor and then goes on a merry rampage ? citizens at random a title card ? reads news of the king's ? throughout the kingdom when the now terrified ? once more ? ? for help he loses his temper and ? their community with lightning ? the moral of our story delivered by a hapless frog just before he is eaten is let well enough alone br br considering the time period when this startling little film was made and considering the fact that it was made by a russian ? at the height of that ? country's civil war it would be easy to see this as a ? about those events ? may or may not have had ? turmoil in mind when he made ? but whatever ? his choice of material the film stands as a ? tale of universal ? ? could be the soviet union italy germany or japan in the 1930s or any country of any era that lets its guard down and is overwhelmed by ? it's a fascinating film even a charming one in its macabre way but its message is no joke\"\n",
      "Predicted Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(preprocessed_reviews)\n",
    "\n",
    "# Output the predictions\n",
    "for review, prediction in zip(sample_reviews, predictions):\n",
    "    sentiment = 'Positive' if prediction > 0.5 else 'Negative'\n",
    "    print(f'Review: \"{review}\"\\nPredicted Sentiment: {sentiment}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
